<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>GPT Voice Assistant</title>
  <style>
    body { font-family: sans-serif; margin: 30px; }
    #mic-btn { font-size: 20px; padding: 10px 30px; }
    #status { margin-top: 20px; }
    #output { margin-top: 30px; font-size: 18px; white-space: pre-wrap; }
    #audio-player { margin-top: 20px; }
  </style>
</head>
<body>
  <h2>GPT Voice Assistant (Демо)</h2>
  <button id="mic-btn">🎤 Говорить</button>
  <div id="status"></div>
  <div id="output"></div>
  <audio id="audio-player" controls style="display:none"></audio>

  <script>
    const OPENAI_PROXY_URL = "https://openai-gpt-proxy.onrender.com/gpt";
    const PROXY_URL = "https://elevenlabs-render-proxy.onrender.com/stream";
    const VOICE_ID = "Yko7PKHZNXotIFUBG7I9";

    let messages = [
      { role: "system", content: "Ты дружелюбный голосовой ассистент." }
    ];
    let listening = false;

    async function recognizeSpeech() {
      return new Promise((resolve, reject) => {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) {
          alert("SpeechRecognition не поддерживается");
          return reject("no-browser-support");
        }
        const recognition = new SpeechRecognition();
        recognition.lang = "ru-RU";
        recognition.start();
        document.getElementById("status").innerText = "🎙️ Говори...";
        recognition.onresult = (event) => {
          const text = event.results[0][0].transcript;
          recognition.stop();
          document.getElementById("status").innerText = "";
          resolve(text);
        };
        recognition.onerror = (err) => {
          document.getElementById("status").innerText = "Ошибка распознавания";
          recognition.stop();
          reject(err.error);
        };
      });
    }

    async function askGPT() {
      const res = await fetch(OPENAI_PROXY_URL, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ model: "gpt-3.5-turbo", messages })
      });
      const data = await res.json();
      if (data.choices && data.choices[0] && data.choices[0].message) {
        return data.choices[0].message.content;
      } else {
        throw new Error("GPT ошибка: " + JSON.stringify(data));
      }
    }

    async function playTTS(text) {
      document.getElementById("status").innerText = "Озвучка ответа...";
      const res = await fetch(PROXY_URL, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          text,
          voice_id: VOICE_ID,
          model_id: "eleven_multilingual_v2",
          output_format: "mp3_44100_128"
        })
      });
      const audioData = await res.arrayBuffer();
      const blob = new Blob([audioData], { type: "audio/mpeg" });
      const audioUrl = URL.createObjectURL(blob);
      const audio = document.getElementById("audio-player");
      audio.src = audioUrl;
      audio.style.display = "block";
      await audio.play();
      document.getElementById("status").innerText = "";
    }

    async function mainLoop() {
      if (listening) return;
      listening = true;

      try {
        while (true) {
          const userText = await recognizeSpeech();
          messages.push({ role: "user", content: userText });
          document.getElementById("output").innerText += `🧑: ${userText}\n`;

          const gptAnswer = await askGPT();
          messages.push({ role: "assistant", content: gptAnswer });
          document.getElementById("output").innerText += `🤖: ${gptAnswer}\n`;

          await playTTS(gptAnswer);
        }
      } catch (e) {
        document.getElementById("status").innerText = "Ошибка: " + e;
      } finally {
        listening = false;
      }
    }

    document.getElementById("mic-btn").onclick = () => {
      document.getElementById("output").innerText = "";
      mainLoop();
    };
  </script>
</body>
</html>
