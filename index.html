<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>GPT Voice Assistant</title>
  <style>
    body { font-family: sans-serif; margin: 30px; }
    #mic-btn { font-size: 20px; padding: 10px 30px; }
    #status { margin-top: 20px; }
    #output { margin-top: 30px; font-size: 18px; white-space: pre-wrap; }
    #audio-player { margin-top: 20px; display: none; }
  </style>
</head>
<body>
  <h2>GPT Voice Assistant (WebSocket Edition)</h2>
  <button id="mic-btn">üé§ –ù–∞—á–∞—Ç—å</button>
  <div id="status"></div>
  <div id="output"></div>
  <audio id="audio-player" autoplay></audio>

  <script>
    const OPENAI_PROXY_URL = "https://openai-gpt-proxy.onrender.com/gpt";
    const SOCKET_URL = "wss://elevenlabs-render-proxy.onrender.com";

    const VOICE_ID = "Yko7PKHZNXotIFUBG7I9";
    let messages = [
      { role: "system", content: "–¢—ã –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –∏ –≥—Ä—É–±—ã–π —É–≥–æ–ª–æ–≤–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –æ–±—â–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —É–≥–æ–ª–æ–≤–Ω–æ–π —Ñ–µ–Ω–µ." }
    ];
    let isRunning = false;

    async function recognizeSpeech(timeout = 10000) {
      return new Promise((resolve, reject) => {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) return reject("SpeechRecognition –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è");

        const recognition = new SpeechRecognition();
        recognition.lang = "ru-RU";
        recognition.interimResults = false;

        const timer = setTimeout(() => {
          recognition.stop();
          reject("‚è±Ô∏è –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏—Å—Ç–µ–∫–ª–æ");
        }, timeout);

        recognition.onstart = () => {
          document.getElementById("status").innerText = "üéôÔ∏è –°–ª—É—à–∞—é...";
        };

        recognition.onresult = (event) => {
          clearTimeout(timer);
          recognition.stop();
          const text = event.results[0][0].transcript;
          document.getElementById("status").innerText = "";
          resolve(text);
        };

        recognition.onerror = (err) => {
          clearTimeout(timer);
          recognition.stop();
          reject(err.error);
        };

        recognition.start();
      });
    }

    async function askGPT() {
      const res = await fetch(OPENAI_PROXY_URL, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ model: "gpt-4o", messages })
      });
      const data = await res.json();
      return data.choices?.[0]?.message?.content || "–û—à–∏–±–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT";
    }

    async function playTTS(text) {
      document.getElementById("status").innerText = "üîä –û–∑–≤—É—á–∫–∞ (WebSocket)...";

      const audio = document.getElementById("audio-player");
      audio.src = "";
      audio.load();

      const mediaSource = new MediaSource();
      audio.src = URL.createObjectURL(mediaSource);

      const socket = new WebSocket(SOCKET_URL);

      socket.addEventListener("open", () => {
        setTimeout(() => {
          socket.send(JSON.stringify({ text }));
        }, 150); // ‚è±Ô∏è –Ω–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π —Ç–µ–∫—Å—Ç–∞
      });

      mediaSource.addEventListener("sourceopen", () => {
        const sourceBuffer = mediaSource.addSourceBuffer("audio/mpeg");

        socket.addEventListener("message", async (event) => {
          const chunk = event.data;

          if (typeof chunk === "string" && chunk.includes("error")) {
            console.warn("–û—à–∏–±–∫–∞ –∏–∑ —Å–µ—Ä–≤–µ—Ä–∞:", chunk);
            document.getElementById("status").innerText = "‚õî –û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏";
            socket.close();
            return;
          }

          if (sourceBuffer.updating) {
            await new Promise(resolve => sourceBuffer.addEventListener("updateend", resolve, { once: true }));
          }

          sourceBuffer.appendBuffer(await chunk.arrayBuffer());
        });

        socket.addEventListener("close", () => {
          if (!sourceBuffer.updating) mediaSource.endOfStream();
        });
      });

      await Promise.race([
        new Promise((resolve) => {
          audio.onended = resolve;
          audio.onerror = resolve;
        }),
        new Promise((resolve) => setTimeout(resolve, 5000))
      ]);

      document.getElementById("status").innerText = "";
    }

    async function dialogLoop() {
      if (isRunning) return;
      isRunning = true;
      try {
        while (true) {
          await new Promise(r => setTimeout(r, 600));
          const userText = await recognizeSpeech();
          messages.push({ role: "user", content: userText });
          document.getElementById("output").innerText += `üßë: ${userText}\n`;

          const reply = await askGPT();
          messages.push({ role: "assistant", content: reply });
          document.getElementById("output").innerText += `ü§ñ: ${reply}\n`;

          await playTTS(reply);
        }
      } catch (err) {
        document.getElementById("status").innerText = "‚õî " + err;
      } finally {
        isRunning = false;
      }
    }

    document.getElementById("mic-btn").onclick = () => {
      document.getElementById("output").innerText = "";
      dialogLoop();
    };

    window.addEventListener("load", () => {
      try {
        const Recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!Recognition) return;
        const warmup = new Recognition();
        warmup.lang = "ru-RU";
        warmup.onstart = () => warmup.abort();
        warmup.start();
      } catch (e) {
        console.warn("STT warmup failed:", e);
      }
    });
  </script>
</body>
</html>
